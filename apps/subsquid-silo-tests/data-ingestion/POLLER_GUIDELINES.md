# Poller Guidelines - R√®gles √† Respecter pour le Futur

## üéØ Principe Fondamental

**OBJECTIF:** R√©cup√©rer 100% des march√©s actifs de Polymarket sans filtrage agressif.

**R√àGLE D'OR:** Si un market est `ACTIVE` dans l'API Polymarket, il DOIT √™tre dans notre DB.

---

## üìã Architecture Obligatoire: 3 Passes

### PASS 1: Fetch /events (Markets Group√©s)

**Endpoint:** `GET https://gamma-api.polymarket.com/events`

**Param√®tres OBLIGATOIRES:**
```
?closed=false           ‚Üê CRITICAL: Seulement events actifs
&order=volume           ‚Üê CRITICAL: Pas order=id (probl√®me pagination!)
&ascending=false        ‚Üê Plus gros volumes en premier
&limit=200              ‚Üê Max par page
&offset={X}             ‚Üê Pagination
```

**Pourquoi `order=volume` est CRITIQUE:**

```
‚ùå BAD: order=id
  - Latest event ID: ~900,000
  - Super Bowl event ID: 23,656
  - Pages n√©cessaires: ~4,400 pages!
  - Avec max_pages=50 ‚Üí JAMAIS atteint

‚úÖ GOOD: order=volume
  - Super Bowl: Position #1 (volume $494M)
  - F1 Championship: Position #5
  - NYC Mayor: Position #2
  - Avec max_pages=50 ‚Üí Tous les gros events couverts
```

**Pagination:**
- `max_pages`: Minimum 100 (mieux: 200)
- `limit`: 200 events par page
- Coverage: ~20,000-40,000 events

**Processing:**
```python
for event in events:
    markets = event.get("markets", [])
    for market in markets:
        # CRITICAL: Enrich avec event parent
        enriched = self._enrich_market_from_event(market, event)

        # enriched['events'] DOIT contenir:
        # [{
        #     "event_id": event.get("id"),
        #     "event_slug": event.get("slug"),
        #     "event_title": event.get("title"),
        #     "event_volume": event.get("volume"),
        #     "event_category": event.get("category")
        # }]
```

---

### PASS 2: Volume-Based Continuous Distribution

**Strat√©gie:** Prioriser les march√©s √† fort volume (97% du volume de trading)

**Target:** 900 march√©s/minute (15 march√©s/seconde)
- **HIGH** (>100K): 700/min (12/cycle) - 97% du volume total
- **MEDIUM** (10K-100K): 180/min (3/cycle) - 2.6% du volume
- **SMALL** (1K-10K): 20/min (1 tous les 3 cycles) - 0.4% du volume

**Endpoint:** `GET https://gamma-api.polymarket.com/markets`

**M√©thode:**
```python
# 1. Query DB par tier de volume
tier_ids = db.get_markets_by_volume_tier(min_vol=100000, limit=1200)

# 2. Rotation dans chaque tier
rotation_offset = poll_count % len(tier_ids)
selected_ids = tier_ids[rotation_offset:rotation_offset + 12]

# 3. Fetch via bulk API
markets = fetch_markets_bulk(selected_ids)  # ?id=X,Y,Z&limit=500

# 4. Pr√©servation donn√©es DB
for market in markets:
    if market_id in events_by_market:
        enriched['events'] = preserved['events']  # Si non-vide
        enriched['category'] = preserved['category']  # Si manquant
```

**Pr√©servation CRITIQUE:**
- Events et category charg√©s depuis DB AVANT update
- Overwrite seulement si nouvelles donn√©es non-vides
- Utilise CASE statement dans `upsert_markets_poll()` (d√©j√† en place)

**Performance:**
- HIGH volume: Couvert en ~1.6 minutes (vs 2.8h rotation)
- MEDIUM volume: Couvert en ~8 minutes
- Charge API: 76 march√©s/cycle (stable, pas de pics)
- Rate limiting: ~2 appels/sec (bien sous limite 20/sec)

**R√àGLE CRITIQUE: Pr√©servation des Events**

```python
# ‚ùå BAD: Overwrite events avec []
enriched = self._parse_standalone_market(market)
# enriched['events'] = []  ‚Üê √âcrase les events de PASS 1!

# ‚úÖ GOOD: Pr√©server events de PASS 1
enriched = self._parse_standalone_market(market)

# Charger events existants depuis DB
events_by_market = load_from_db()

# Ne pr√©server QUE si events non-vide
if events_by_market[market_id] and len(events_by_market[market_id]) > 0:
    enriched['events'] = events_by_market[market_id]
# Sinon, laisser PASS 1 remplir au prochain cycle
```

**Exclusions:**
- SKIP markets d√©j√† trait√©s dans PASS 1 (`if market_id in exclude_ids: continue`)
- SKIP markets non-existants en DB (`if market_id not in existing_ids: continue`)

---

### PASS 3: Lifecycle + Resolution Detection

**Op√©rations:**

1. **Mark expired markets as CLOSED:**
```python
UPDATE subsquid_markets_poll
SET status = 'CLOSED',
    resolution_status = 'PROPOSED'
WHERE status = 'ACTIVE'
  AND end_date < NOW() - INTERVAL '1 hour'
```

2. **Detect winning outcomes:**
```python
# Via API field
outcome = market_data.get("outcome")  # "Yes" ou "No"

# Via prix finaux
if outcome_prices == [1.0, 0.0]:
    winning_outcome = 1  # Yes gagne
elif outcome_prices == [0.0, 1.0]:
    winning_outcome = 0  # No gagne
```

3. **Update resolution_status:**
```
PENDING ‚Üí Market ouvert
PROPOSED ‚Üí Market ferm√©, outcome en attente (<1h)
RESOLVED ‚Üí Outcome confirm√©, redeem disponible
```

---

## üö´ Filtres INTERDITS

### ‚ùå NE JAMAIS Filtrer Par:

1. **Date de cr√©ation**
   - Market cr√©√© en 2024? ‚Üí GARDER si ACTIVE
   - Market cr√©√© en 2020? ‚Üí GARDER si ACTIVE

2. **Prix extr√™mes**
   - Prix 0.001/0.999? ‚Üí VALIDE! (high-confidence market)
   - Prix 0.0001/0.9999? ‚Üí VALIDE! (quasi-certain outcome)
   - Seul filtre OK: prix VIDES (`[]`)

3. **tradeable=false**
   - Market avec `tradeable=false` MAIS `closed=false`? ‚Üí GARDER comme ACTIVE
   - C'est juste une pause temporaire

4. **Volume minimum**
   - Market avec $0.01 volume? ‚Üí GARDER si ACTIVE
   - Utilisateurs peuvent avoir des positions dessus!

### ‚úÖ Seuls Filtres Autoris√©s:

1. **outcome_prices vides**
   ```python
   if not outcome_prices or len(outcome_prices) == 0:
       return False  # Market illiquid/mort
   ```

2. **Status API**
   ```python
   # Respecter le champ "closed" de l'API
   if market.get("closed") == True:
       status = "CLOSED"
   ```

---

## üîÑ Logique de R√©solution (3 Cat√©gories)

### Cat√©gorie 1: ACTIVE en pause

**Crit√®res:**
- `end_date` NULL ou future
- `closed = false`
- `tradeable` peut √™tre false (ignor√©!)

**Action:**
```python
status = "ACTIVE"
resolution_status = "PENDING"
winning_outcome = None
```

---

### Cat√©gorie 2: Expir√© r√©cemment

**Crit√®res:**
- `end_date` pass√©e

**Action (progression temporelle):**

```python
# <1h apr√®s expiration
if end_date < now and end_date > (now - 1h):
    status = "CLOSED"
    resolution_status = "PROPOSED"
    winning_outcome = None  # Pas encore dispo

# >1h apr√®s expiration
if end_date < (now - 1h):
    status = "CLOSED"
    outcome = extract_winning_outcome(market_data)
    if outcome is not None:
        resolution_status = "RESOLVED"
        winning_outcome = outcome
    else:
        resolution_status = "PROPOSED"
```

---

### Cat√©gorie 3: Ferm√© pr√©matur√©ment

**Crit√®res:**
- `end_date` future ou NULL
- `closed = true`

**Exemples:**
- Lewis Hamilton F1 (√©limin√© math√©matiquement)
- Market suspendu pour raisons l√©gales

**Action:**
```python
status = "CLOSED"
outcome = extract_winning_outcome(market_data)
if outcome is not None:
    resolution_status = "RESOLVED"
    winning_outcome = outcome
else:
    resolution_status = "PROPOSED"
```

---

## üìä Champs DB Obligatoires

Tous les markets dans `subsquid_markets_poll` DOIVENT avoir:

### Champs de Base:
- `market_id` (PK)
- `title`
- `status` ("ACTIVE" ou "CLOSED")
- `slug`
- `condition_id`

### Champs de Pricing:
- `outcome_prices` (ARRAY) ‚Üê CRITICAL
- `outcomes` (ARRAY)
- `last_mid` (calculated)
- `volume`, `volume_24hr`, `liquidity`

### Champs Temporels:
- `end_date`
- `created_at`
- `updated_at`

### Champs de R√©solution (NOUVEAUX):
- `resolution_status` ‚Üê CRITICAL pour redeem
- `winning_outcome` ‚Üê 0 ou 1
- `resolution_date`

### Champs de Grouping:
- `events` (JSONB array) ‚Üê CRITICAL pour UI
- `polymarket_url` ‚Üê CRITICAL pour UX

### Champs Techniques:
- `clob_token_ids` (pour trading)
- `tokens` (pour outcome matching)
- `tradeable`, `accepting_orders`

---

## üèóÔ∏è Structure du Champ `events`

### Format OBLIGATOIRE:

```json
[
  {
    "event_id": "23656",
    "event_slug": "super-bowl-champion-2026-731",
    "event_title": "Super Bowl Champion 2026",
    "event_volume": 494341363.56,
    "event_category": "Sports"
  }
]
```

### Cas d'Usage:

**Event group√© (33 markets Super Bowl):**
```json
{
  "market_id": "540236",
  "title": "Will the Tennessee Titans win Super Bowl 2026?",
  "events": [{ "event_title": "Super Bowl Champion 2026", ... }]
}
```

**Market standalone (Xi Jinping):**
```json
{
  "market_id": "551963",
  "title": "Xi Jinping out in 2025?",
  "events": []
}
```

### Affichage Bot:

```python
# market_data_layer.py ligne 826+
def _group_markets_by_events(markets):
    for market in markets:
        events = market.get('events', [])

        # Si events non-vide ET event_title != market title ‚Üí GROUP
        if events and events[0].get('event_title') != market['title']:
            # Grouper sous event parent
            event_groups[event_id] = {
                'event_title': events[0]['event_title'],
                'markets': [...]  # Tous les markets de l'event
            }
        else:
            # Individual market
            individual_markets.append(market)
```

---

## ‚ö° Performance & Rate Limiting

### Pagination Limits:

```python
# PASS 1: /events
max_pages = 200       # Coverage: ~40,000 events
limit = 200           # Events par page
sleep = 0.05s         # Entre pages

# PASS 2: /markets
max_pages = 200       # Coverage: ~40,000 markets
limit = 200           # Markets par page
sleep = 0.05s

# PASS 3: /markets?closed=true
max_pages = 50        # Seulement r√©cents
limit = 200
```

### Rate Limiting:

```python
# Entre pages
await asyncio.sleep(0.05)  # 50ms

# Entre batches enrichment
if batch_num % 10 == 0:
    await asyncio.sleep(0.1)  # 100ms

# Si 429 (rate limited)
await asyncio.sleep(2.0)  # 2 secondes
```

### Timeouts:

```python
httpx.AsyncClient(timeout=30.0)  # 30 secondes
db.execute(timeout=60.0)         # 60 secondes
```

---

## üêõ Pi√®ges √† √âviter

### 1. Pagination par ID au lieu de Volume

```python
# ‚ùå BAD
url = "/events?order=id&ascending=false"
# ‚Üí Events r√©cents en premier
# ‚Üí Gros events (Super Bowl ID 23656) loin dans pagination

# ‚úÖ GOOD
url = "/events?order=volume&ascending=false"
# ‚Üí Super Bowl position #1
# ‚Üí F1 position #5
# ‚Üí Tous les gros events dans 50 premi√®res pages
```

### 2. Pr√©server events = []

```python
# ‚ùå BAD
if events_by_market[market_id]:
    preserve_events()
# ‚Üí events=[] est falsy, donc jamais pr√©serv√©
# ‚Üí PASS 1 ne peut jamais fill in!

# ‚úÖ GOOD
if events_by_market[market_id] and len(events_by_market[market_id]) > 0:
    preserve_events()
# ‚Üí events=[] n'est pas pr√©serv√©
# ‚Üí PASS 1 peut fill in au prochain cycle
```

### 3. Filtrer par Date de Cr√©ation

```python
# ‚ùå BAD
if created_at < datetime(2025, 8, 1):
    return False  # Exclut markets anciens
# ‚Üí Exclut Super Bowl, F1, NYC Mayor (cr√©√©s avant ao√ªt)

# ‚úÖ GOOD
# Pas de filtre de date!
# Seul crit√®re: market ACTIVE dans API
```

### 4. Filtrer par Prix Extr√™mes

```python
# ‚ùå BAD
if price < 0.01 or price > 0.99:
    return False  # "Invalid price"
# ‚Üí Exclut 2,318 markets ($1.7B volume!)
# ‚Üí Ex: Government shutdown 0.004/0.996

# ‚úÖ GOOD
if not outcome_prices or len(outcome_prices) == 0:
    return False  # Seulement si vide
# ‚Üí Prix extr√™mes sont VALIDES (high-confidence markets)
```

### 5. Overwrite events sans Check

```python
# ‚ùå BAD
enriched = parse_market(market)
enriched['events'] = []  # √âcrase toujours!

# ‚úÖ GOOD
enriched = parse_market(market)
# Ne pas toucher √† enriched['events']
# Laisser la logique de pr√©servation g√©rer
```

---

## üìä Monitoring Obligatoire

### Logs √† Surveiller (Railway):

**Chaque cycle DOIT afficher:**
```
‚úÖ [CYCLE #X] Total upserted: Y in Zs
üìä [PASS 1] X events ‚Üí Y markets
üìä [PASS 2] Updated X/Y existing markets (Z% coverage)
‚úÖ [PASS 3] Updated X markets
```

**Alertes si:**
- ‚ùå Upsert < 100 markets par cycle (probl√®me API)
- ‚ùå PASS 2 coverage < 50% (probl√®me pagination)
- ‚ùå Erreurs "‚ùå" r√©p√©t√©es

### Queries de Sant√© (Quotidiennes):

```sql
-- Check 1: Coverage ACTIVE markets
SELECT
    COUNT(*) as active_count,
    COUNT(*) FILTER (WHERE updated_at > NOW() - INTERVAL '1 hour') as fresh_1h,
    COUNT(*) FILTER (WHERE updated_at > NOW() - INTERVAL '6 hours') as fresh_6h
FROM subsquid_markets_poll
WHERE status = 'ACTIVE';

-- Attendu:
-- active_count: >8,000
-- fresh_1h: >80%
-- fresh_6h: >95%


-- Check 2: Events grouping
SELECT
    COUNT(*) as total_active,
    COUNT(*) FILTER (WHERE jsonb_array_length(events) > 0) as has_events,
    COUNT(*) FILTER (WHERE events = '[]'::jsonb) as standalone
FROM subsquid_markets_poll
WHERE status = 'ACTIVE';

-- Attendu:
-- has_events: ~6,500 (markets group√©s)
-- standalone: ~2,500 (markets individuels)


-- Check 3: URLs
SELECT
    COUNT(*) FILTER (WHERE polymarket_url LIKE 'https://polymarket.com/%') as has_url,
    COUNT(*) as total
FROM subsquid_markets_poll
WHERE status = 'ACTIVE';

-- Attendu: has_url = total (100%)


-- Check 4: Resolution tracking
SELECT
    resolution_status,
    COUNT(*),
    SUM(volume)
FROM subsquid_markets_poll
GROUP BY resolution_status;

-- Attendu:
-- PENDING: majorit√©
-- PROPOSED: quelques dizaines
-- RESOLVED: quelques centaines
```

---

## üîß Modifications Futures: Checklist

Avant de modifier le poller, v√©rifier:

- [ ] Le changement ne filtre PAS de markets ACTIVE
- [ ] Les events ne sont PAS √©cras√©s accidentellement
- [ ] L'ordre de pagination est toujours `order=volume` pour `/events`
- [ ] Les 3 cat√©gories de r√©solution sont respect√©es
- [ ] La logique de pr√©servation est intacte
- [ ] Les tests de validation passent (voir POLLER_VALIDATION_TESTS.md)

---

## üì¶ D√©ploiement: Proc√©dure Standard

### Avant Deploy:

```bash
# 1. Tester localement (si possible)
cd apps/subsquid-silo-tests/data-ingestion
export DATABASE_URL="postgresql://..."
python -m src.main  # Test 1 cycle

# 2. V√©rifier linting
pylint src/polling/poller.py

# 3. Review changements
git diff src/polling/poller.py
```

### Deploy:

```bash
# Commit avec message descriptif
git add .
git commit -m "feat(poller): [description]

Changes:
- [change 1]
- [change 2]

BREAKING: None/Yes
"

# Push (auto-deploy si Railway watch)
git push origin main

# OU manual deploy
railway up -s poller
```

### Apr√®s Deploy (Monitor 1h):

```bash
# Watch logs
railway logs -s poller --follow

# V√©rifier coverage (apr√®s 5-10 minutes)
# Run queries de sant√© (ci-dessus)

# Si probl√®me ‚Üí Rollback
git revert HEAD
railway up -s poller
```

---

## üÜò Troubleshooting Guide

### Probl√®me: "Markets Super Bowl ont events = []"

**Cause possible:**
1. PASS 1 n'atteint pas l'event (pagination insuffisante)
2. PASS 2 √©crase les events

**Solution:**
```bash
# Check logs
railway logs -s poller | grep "PASS 1"
# Chercher: "[PASS 1] X events ‚Üí Y markets"

# Si Y < 1000 ‚Üí Probl√®me pagination
# Fix: Augmenter max_pages ou v√©rifier order=volume
```

**Validation API:**
```bash
curl "https://gamma-api.polymarket.com/events?limit=10&order=volume&ascending=false" \
  | python3 -c "import sys,json; [print(e['title']) for e in json.load(sys.stdin)[:5]]"

# Super Bowl DOIT √™tre dans top 5
```

---

### Probl√®me: "Markets filtr√©s/manquants"

**Validation:**
```sql
-- Comparer avec API
-- API dit ACTIVE, DB dit absent ‚Üí Filtre trop agressif

SELECT market_id, title
FROM subsquid_markets_poll
WHERE market_id = '540236';  -- Tennessee Titans

-- Si absent ‚Üí Check filtres dans _is_market_valid()
```

**Fix:**
- Supprimer tout filtre sauf `outcome_prices` vide
- V√©rifier aucun `continue` pr√©matur√© dans loops

---

### Probl√®me: "Resolution tracking ne fonctionne pas"

**Validation:**
```sql
-- Markets expir√©s depuis >1h devraient avoir outcome
SELECT market_id, title, resolution_status, winning_outcome
FROM subsquid_markets_poll
WHERE end_date < NOW() - INTERVAL '2 hours'
  AND status = 'CLOSED'
LIMIT 10;

-- Si winning_outcome = NULL partout ‚Üí Bug extraction
```

**Fix:**
- V√©rifier `_extract_winning_outcome()` fonctionne
- V√©rifier API retourne bien le champ "outcome"
- V√©rifier prix finaux [1.0, 0.0] d√©tect√©s

---

## üìö Documentation de R√©f√©rence

### Fichiers Importants:

1. **poller.py** - Code principal (3 passes)
2. **db/client.py** - Upsert logic
3. **market_data_layer.py** - Validation markets
4. **POLLER_VALIDATION_TESTS.md** - Tests apr√®s deploy
5. **DEPLOYMENT_GUIDE.md** - Proc√©dure d√©ploiement

### API Polymarket:

**Endpoints:**
- `/events` - Events group√©s (TOUJOURS order=volume!)
- `/markets` - Markets standalone
- `/markets/{id}` - Market individuel

**Champs cl√©s:**
- `closed` (boolean) - Market ferm√©?
- `active` ‚Üí `tradeable` dans DB
- `acceptingOrders` ‚Üí `accepting_orders` dans DB
- `outcome` - Outcome gagnant si r√©solu

---

## üéØ Success Metrics

### Coverage (Quotidien):

- [ ] >8,000 ACTIVE markets
- [ ] >95% fresh (<6h old)
- [ ] 100% URL coverage

### Events (Quotidien):

- [ ] ~6,500 markets avec events group√©s
- [ ] 0 events corrompus (backslashes)
- [ ] Super Bowl, F1, NYC Mayor ont events remplis

### Resolution (Quotidien):

- [ ] >100 markets RESOLVED
- [ ] <50 markets PROPOSED depuis >24h (bloqu√©s)
- [ ] 0 markets RESOLVED sans winning_outcome

### Performance:

- [ ] Cycle time <40s
- [ ] CPU Railway <60%
- [ ] Memory <512MB
- [ ] 0 DB timeouts

---

## üöÄ Roadmap Future

### Court Terme (1-2 semaines):

- [ ] Monitor coverage et r√©solution
- [ ] Activer redeem bot automatique
- [ ] Optimiser pagination si n√©cessaire

### Moyen Terme (1-2 mois):

- [ ] Ajouter cache Redis pour events (√©viter refetch)
- [ ] Incremental updates (seulement markets changed)
- [ ] WebSocket pour r√©solutions temps r√©el

### Long Terme (3+ mois):

- [ ] Migration compl√®te vers subsquid_markets_poll
- [ ] Deprecate old markets table
- [ ] Analytics sur r√©solutions

---

**Version:** 2.0
**Date:** Nov 3, 2025
**Auteur:** Team Polycool
**Status:** ‚úÖ Production Guidelines
