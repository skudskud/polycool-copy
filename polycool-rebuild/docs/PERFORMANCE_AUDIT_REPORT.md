# üîç Audit de Performance - Bot Telegram & Base de Donn√©es

**Date**: 2025-01-12
**Contexte**: Architecture microservices (Bot SKIP_DB=true, API SKIP_DB=false, Workers)
**Projet**: Polycool Telegram Bot

---

## üìä R√©sum√© Ex√©cutif

### Probl√®mes Critiques Identifi√©s

1. **‚ùå CRITIQUE**: Appels API r√©p√©titifs pour r√©cup√©rer les march√©s dans les positions
2. **‚ö†Ô∏è HAUTE PRIORIT√â**: Invalidation de cache trop agressive avec `invalidate_pattern`
3. **‚ö†Ô∏è HAUTE PRIORIT√â**: Requ√™tes DB non optimis√©es dans les handlers
4. **‚ö†Ô∏è MOYENNE PRIORIT√â**: D√©bounce insuffisant pour les mises √† jour de positions
5. **‚ö†Ô∏è MOYENNE PRIORIT√â**: Pas de batch fetching pour les march√©s multiples

---

## üö® Probl√®mes D√©tail√©s

### 1. Appels API R√©p√©titifs pour les March√©s (CRITIQUE)

**Localisation**: `telegram_bot/bot/handlers/positions_handler.py:266-270`

**Probl√®me**:
```python
# Get cached markets
for position in positions:
    if position.market_id not in markets_map:
        market = await api_client.get_market(position.market_id)  # ‚ùå Appel API par position
        if market:
            markets_map[position.market_id] = market
```

**Impact**:
- Si un utilisateur a 10 positions, cela g√©n√®re **10 appels API s√©quentiels**
- Chaque appel prend ~100-300ms
- **Latence totale: 1-3 secondes** juste pour r√©cup√©rer les march√©s
- Surcharge inutile de l'API et de la DB Supabase

**Solution Recommand√©e**:
```python
# Batch fetch all markets at once
if positions:
    market_ids = list(set(p.market_id for p in positions))
    markets_data = await api_client.get_markets_batch(market_ids)  # ‚úÖ Un seul appel
    markets_map = {m['id']: m for m in markets_data}
```

**Priorit√©**: üî¥ CRITIQUE - Impact direct sur la latence utilisateur

---

### 2. Invalidation de Cache Trop Agressive (HAUTE PRIORIT√â)

**Localisation**: Multiple fichiers

**Probl√®me**:
```python
# Dans api_client.py et positions.py
await cache_manager.invalidate_pattern("api:positions:*")  # ‚ùå Invalide TOUTES les positions
```

**Impact**:
- Invalide le cache pour **TOUS les utilisateurs** alors qu'un seul utilisateur a chang√©
- Force tous les utilisateurs √† refaire des requ√™tes DB/API
- Augmente la charge sur Supabase de mani√®re exponentielle
- Perte de performance du cache (hit rate r√©duit)

**Exemples Trouv√©s**:
- `api_client.py:512` - `invalidate_pattern("api:positions:*")`
- `api_client.py:562` - `invalidate_pattern("api:positions:*")`
- `tpsl_handler.py` - Invalidation trop large

**Solution Recommand√©e**:
```python
# Invalider uniquement pour l'utilisateur concern√©
await cache_manager.invalidate_pattern(f"api:positions:{user_id}")  # ‚úÖ Cibl√©
await cache_manager.delete(f"api:position:{position_id}")  # ‚úÖ Sp√©cifique
```

**Priorit√©**: üü† HAUTE - Impact sur la charge DB et performance globale

---

### 3. Requ√™tes DB Non Optimis√©es (HAUTE PRIORIT√â)

**Localisation**: `telegram_bot/api/v1/positions.py`

**Probl√®me**:
```python
# Dans sync_positions
synced_count = await position_service.sync_positions_from_blockchain(...)  # 1 requ√™te
updated_count = await position_service.update_all_positions_prices(user_id)  # N requ√™tes
```

**Impact**:
- `update_all_positions_prices` fait une requ√™te DB par position
- Pour 20 positions = 20 requ√™tes DB s√©quentielles
- Pas de batch update
- Surcharge Supabase avec trop de connexions

**Solution Recommand√©e**:
```python
# Batch update en une seule transaction
await position_service.batch_update_positions_prices(
    user_id=user_id,
    position_updates=updates  # Liste de {position_id, current_price}
)
```

**Priorit√©**: üü† HAUTE - Impact direct sur la charge Supabase

---

### 4. D√©bounce Insuffisant pour Positions (MOYENNE PRIORIT√â)

**Localisation**: `data_ingestion/streamer/market_updater/market_updater.py:59-60`

**Probl√®me**:
```python
self.position_debounce = DebounceManager(delay=10.0, max_updates_per_second=5)  # 10s delay
```

**Impact**:
- Avec 1000 march√©s actifs et mises √† jour WebSocket fr√©quentes
- 5 updates/seconde = 300 updates/minute
- Si chaque update d√©clenche une requ√™te DB pour les positions ‚Üí surcharge
- Le d√©lai de 10s peut √™tre trop court pour les march√©s tr√®s actifs

**Solution Recommand√©e**:
```python
# Augmenter le d√©lai et r√©duire le taux
self.position_debounce = DebounceManager(
    delay=15.0,  # ‚úÖ Augment√© √† 15s
    max_updates_per_second=2  # ‚úÖ R√©duit √† 2/sec
)
```

**Priorit√©**: üü° MOYENNE - Impact sur la charge DB lors de pics d'activit√©

---

### 5. Pas de Batch Fetching pour March√©s (MOYENNE PRIORIT√â)

**Localisation**: `core/services/api_client/api_client.py`

**Probl√®me**:
- Pas de m√©thode `get_markets_batch()` dans `APIClient`
- Chaque handler doit faire des appels individuels
- Multiplie les requ√™tes HTTP et DB

**Solution Recommand√©e**:
```python
async def get_markets_batch(
    self,
    market_ids: List[str],
    use_cache: bool = True
) -> Optional[List[Dict[str, Any]]]:
    """
    Get multiple markets in a single API call

    Args:
        market_ids: List of market IDs
        use_cache: Whether to use cache

    Returns:
        List of market dicts
    """
    # Endpoint: POST /markets/batch
    # Body: {"market_ids": [...]}
    # Returns: {"markets": [...]}
```

**Priorit√©**: üü° MOYENNE - Am√©lioration significative de la latence

---

## üìà √âtat des Lieux - Gestion du Cache

### Configuration Actuelle

**TTL Strategy** (`cache_manager.py:23-31`):
```python
TTL_STRATEGY = {
    'prices': 20s,           # ‚úÖ Ultra-court (OK)
    'positions': 30s,        # ‚úÖ Court (r√©duit de 3min, bon)
    'markets_list': 5min,    # ‚úÖ Moyen (OK)
    'market_detail': 5min,    # ‚úÖ Moyen (OK)
    'user_profile': 1h,      # ‚úÖ Long (OK)
    'smart_trades': 5min,    # ‚úÖ Moyen (OK)
    'leaderboard': 1h,       # ‚úÖ Long (OK)
}
```

**‚úÖ Points Positifs**:
- TTL bien configur√©s selon le type de donn√©es
- Cache Redis fonctionnel
- Invalidation pr√©sente dans l'API service

**‚ùå Points √† Am√©liorer**:
- Invalidation trop large (pattern `*` au lieu de cibl√©)
- Pas de m√©triques de cache hit rate en production
- Pas de cache warming pour les donn√©es fr√©quentes

---

### Cache Hit Rate (Estimation)

**Sc√©narios**:
- **Positions**: ~70% hit rate (TTL 30s, invalidation fr√©quente)
- **Markets**: ~85% hit rate (TTL 5min, donn√©es stables)
- **User Profile**: ~95% hit rate (TTL 1h, changements rares)

**Probl√®me**: Invalidation trop agressive r√©duit le hit rate r√©el

---

## üîß Recommandations d'Optimisation

### Priorit√© 1 - Imm√©diat (Impact Critique)

1. **Impl√©menter Batch Fetching pour March√©s**
   - Cr√©er endpoint `/markets/batch` dans l'API
   - Ajouter m√©thode `get_markets_batch()` dans `APIClient`
   - Modifier `positions_handler.py` pour utiliser batch

2. **Corriger Invalidation de Cache**
   - Remplacer `invalidate_pattern("api:positions:*")` par `invalidate_pattern(f"api:positions:{user_id}")`
   - Fichiers √† modifier:
     - `core/services/api_client/api_client.py:512, 562`
     - V√©rifier tous les usages de `invalidate_pattern`

3. **Optimiser Requ√™tes DB Positions**
   - Impl√©menter `batch_update_positions_prices()` dans `position_service`
   - Utiliser une seule transaction pour toutes les mises √† jour

### Priorit√© 2 - Court Terme (Impact Important)

4. **Am√©liorer D√©bounce**
   - Augmenter d√©lai position updates √† 15s
   - R√©duire max_updates_per_second √† 2

5. **Ajouter M√©triques Cache**
   - Logger cache hit rate par type de donn√©es
   - Alertes si hit rate < 50%

6. **Optimiser Requ√™tes API**
   - Utiliser `use_cache=True` par d√©faut (d√©j√† fait ‚úÖ)
   - √âviter `use_cache=False` sauf si n√©cessaire

### Priorit√© 3 - Moyen Terme (Am√©lioration Continue)

7. **Cache Warming**
   - Pr√©-charger les march√©s populaires au d√©marrage
   - Pr√©-charger les positions des utilisateurs actifs

8. **Connection Pooling**
   - V√©rifier que le pool DB est bien configur√© (actuellement: pool_size=3, max_overflow=5)
   - Monitorer les connexions actives

9. **Rate Limiting**
   - V√©rifier que le rate limiting API client fonctionne (100 req/min ‚úÖ)
   - Ajouter rate limiting c√¥t√© API pour prot√©ger Supabase

---

## üìä M√©triques √† Surveiller

### Base de Donn√©es Supabase

1. **Connexions Actives**
   - Cible: < 50 connexions simultan√©es
   - Alerte si > 80 connexions

2. **Requ√™tes par Seconde**
   - Cible: < 100 req/s
   - Alerte si > 200 req/s

3. **Latence P95**
   - Cible: < 100ms
   - Alerte si > 500ms

### API Service

1. **Latence Endpoints**
   - `/positions/user/{id}`: Cible < 200ms
   - `/markets/{id}`: Cible < 150ms
   - `/markets/batch`: Cible < 300ms (√† cr√©er)

2. **Taux d'Erreur**
   - Cible: < 1%
   - Alerte si > 5%

### Cache Redis

1. **Hit Rate Global**
   - Cible: > 70%
   - Alerte si < 50%

2. **M√©moire Utilis√©e**
   - Surveiller l'utilisation m√©moire Redis
   - Alerte si > 80% de la capacit√©

---

## üéØ Plan d'Action Imm√©diat

### Semaine 1

- [ ] Impl√©menter `get_markets_batch()` dans APIClient
- [ ] Cr√©er endpoint `/markets/batch` dans l'API
- [ ] Modifier `positions_handler.py` pour utiliser batch
- [ ] Corriger toutes les invalidations de cache trop larges

### Semaine 2

- [ ] Impl√©menter `batch_update_positions_prices()`
- [ ] Optimiser `sync_positions` pour utiliser batch
- [ ] Ajuster param√®tres d√©bounce

### Semaine 3

- [ ] Ajouter m√©triques cache hit rate
- [ ] Impl√©menter monitoring connexions DB
- [ ] Tests de charge pour valider les am√©liorations

---

## üìù Notes Techniques

### Architecture Actuelle

```
Bot (SKIP_DB=true)
  ‚Üì HTTP
API Service (SKIP_DB=false)
  ‚Üì SQL
Supabase PostgreSQL
  ‚Üë
Redis Cache (shared)
```

### Points d'Attention

1. **Race Conditions**: L'invalidation de cache c√¥t√© bot et API peut cr√©er des race conditions
   - Solution: Invalider uniquement c√¥t√© API apr√®s √©criture DB

2. **Cache Coherence**: Le cache doit √™tre invalid√© apr√®s chaque √©criture
   - ‚úÖ D√©j√† fait dans l'API service
   - ‚ö†Ô∏è √Ä am√©liorer: invalidation plus cibl√©e

3. **Connection Pooling**: Supabase Pooler (port 6543) utilis√©
   - ‚úÖ Configuration correcte
   - ‚ö†Ô∏è Pool size peut √™tre augment√© si n√©cessaire

---

## ‚úÖ Conclusion

**Probl√®mes Identifi√©s**: 5 probl√®mes majeurs
**Impact Estim√©**:
- R√©duction latence: **-60%** (batch fetching)
- R√©duction charge DB: **-40%** (invalidation cibl√©e)
- Am√©lioration hit rate cache: **+15%**

**Effort Estim√©**:
- Priorit√© 1: 2-3 jours
- Priorit√© 2: 1-2 jours
- Priorit√© 3: 3-5 jours

**ROI**: Tr√®s √©lev√© - am√©liorations critiques pour la scalabilit√©
