# Analyse de Latence - Commande /smart_trading

## ğŸ” ProblÃ¨mes IdentifiÃ©s

### 1. **RÃ©solution SÃ©quentielle des MarchÃ©s (CRITIQUE)**

**Localisation** : `telegram_bot/handlers/smart_trading/view_handler.py:144-159`

**ProblÃ¨me** :
```python
for trade in trades_data:
    position_id = trade.get('position_id')
    if not position_id:
        continue

    # Check cache first
    if position_id in position_id_to_market:
        market = position_id_to_market[position_id]
    else:
        try:
            market = await _resolve_market_by_position_id(position_id, context)  # âš ï¸ SÃ‰QUENTIEL
            if market:
                position_id_to_market[position_id] = market
```

**Impact** :
- Si on a 50 trades, cela fait **50 appels API sÃ©quentiels**
- Chaque appel peut prendre jusqu'Ã  **10 secondes** (timeout)
- **Temps total potentiel** : 50 Ã— 10s = **500 secondes (8+ minutes)** dans le pire cas
- **Temps rÃ©el typique** : 50 Ã— 0.5s = **25 secondes** (si chaque appel prend 500ms)

**Solution** : ParallÃ©liser avec `asyncio.gather()` ou `asyncio.create_task()`

---

### 2. **Pas de ParallÃ©lisation des Appels API**

**Localisation** : `telegram_bot/handlers/smart_trading/callbacks.py:28-71`

**ProblÃ¨me** :
- Chaque rÃ©solution de marchÃ© fait un appel HTTP sÃ©parÃ©
- Les appels sont faits un par un au lieu d'Ãªtre parallÃ©lisÃ©s
- Pas de limite de concurrence (peut surcharger l'API)

**Impact** :
- Latence cumulative : si 50 trades, 50 appels sÃ©quentiels
- Pas d'utilisation optimale des connexions HTTP

**Solution** : Utiliser `asyncio.gather()` avec un semaphore pour limiter la concurrence

---

### 3. **Timeout de 10 Secondes par RequÃªte**

**Localisation** : `core/services/api_client/api_client.py:37`

**ProblÃ¨me** :
```python
self.client = httpx.AsyncClient(
    timeout=10.0,  # âš ï¸ 10 secondes par requÃªte
    follow_redirects=True
)
```

**Impact** :
- Si une requÃªte est lente, elle bloque jusqu'Ã  10 secondes
- Pas de timeout plus court pour les rÃ©solutions de marchÃ©
- Peut causer des timeouts Telegram (30 secondes max)

**Solution** : RÃ©duire le timeout pour les rÃ©solutions de marchÃ© (ex: 3 secondes)

---

### 4. **Pas de Cache au Niveau du Handler**

**Localisation** : `telegram_bot/handlers/smart_trading/view_handler.py:135-171`

**ProblÃ¨me** :
- Le cache `position_id_to_market` est uniquement en mÃ©moire dans `context.user_data`
- Perdu entre les sessions utilisateur
- Pas de cache Redis partagÃ© pour les rÃ©solutions de marchÃ©

**Impact** :
- Chaque utilisateur doit rÃ©soudre les mÃªmes marchÃ©s
- Pas de rÃ©utilisation entre utilisateurs
- Latence rÃ©pÃ©tÃ©e pour les mÃªmes `position_id`

**Solution** : Utiliser Redis cache pour les rÃ©solutions de marchÃ© (TTL: 5-10 minutes)

---

### 5. **Batch Resolution Inefficace**

**Localisation** : `core/services/smart_trading/service.py:392-432`

**ProblÃ¨me** :
```python
async with get_db() as db:
    for position_id in position_ids:  # âš ï¸ Boucle sÃ©quentielle
        try:
            result = await db.execute(
                select(Market.title).where(
                    Market.is_active == True,
                    Market.clob_token_ids.op('@>')([position_id])
                ).limit(1)
            )
```

**Impact** :
- MÃªme en mode DB, les requÃªtes sont faites une par une
- Pas de vraie requÃªte batch SQL
- N requÃªtes au lieu d'une seule

**Solution** : Utiliser une requÃªte SQL avec `ANY()` ou `IN` pour rÃ©soudre tous les position_ids en une seule fois

---

### 6. **Double RÃ©solution des MarchÃ©s**

**Localisation** : `telegram_bot/handlers/smart_trading/view_handler.py:135-171`

**ProblÃ¨me** :
- Le service `get_recent_recommendations_cached` rÃ©sout dÃ©jÃ  les titres de marchÃ©
- Le handler les rÃ©sout Ã  nouveau pour obtenir les URLs Polymarket
- Double travail pour les mÃªmes donnÃ©es

**Impact** :
- Latence supplÃ©mentaire inutile
- RequÃªtes redondantes

**Solution** : Inclure les URLs Polymarket dans la rÃ©ponse du service/API

---

### 7. **Pas de Limite de Concurrence**

**ProblÃ¨me** :
- Si on parallÃ©lise les appels, rien n'empÃªche de faire 50 requÃªtes simultanÃ©es
- Peut surcharger l'API ou la base de donnÃ©es
- Peut causer des erreurs de rate limiting

**Solution** : Utiliser un `asyncio.Semaphore` pour limiter Ã  5-10 requÃªtes simultanÃ©es

---

## ğŸ“Š Estimation de Latence Actuelle

### ScÃ©nario Typique (50 trades)
- **RÃ©cupÃ©ration des trades** : 0.5-1s (cache Redis)
- **RÃ©solution des 50 marchÃ©s (sÃ©quentiel)** : 50 Ã— 0.5s = **25 secondes**
- **Filtrage et formatage** : 0.1s
- **Total** : **~26 secondes** âš ï¸

### ScÃ©nario Pire Cas
- **RÃ©cupÃ©ration des trades** : 2s (cache miss)
- **RÃ©solution des 50 marchÃ©s (sÃ©quentiel)** : 50 Ã— 10s = **500 secondes** (timeout)
- **Total** : **~502 secondes (8+ minutes)** âŒ

### ScÃ©nario OptimisÃ© (avec parallÃ©lisation)
- **RÃ©cupÃ©ration des trades** : 0.5-1s (cache Redis)
- **RÃ©solution des 50 marchÃ©s (parallÃ¨le, 10 Ã  la fois)** : 5 Ã— 0.5s = **2.5 secondes**
- **Filtrage et formatage** : 0.1s
- **Total** : **~3-4 secondes** âœ…

---

## ğŸš€ Solutions RecommandÃ©es

### Solution 1 : ParallÃ©liser les RÃ©solutions de MarchÃ© (PRIORITÃ‰ HAUTE)

```python
# Dans _display_trades_page
import asyncio

# Collecter tous les position_ids uniques
position_ids_to_resolve = [
    trade.get('position_id')
    for trade in trades_data
    if trade.get('position_id') and trade.get('position_id') not in position_id_to_market
]

# ParallÃ©liser les rÃ©solutions (limite de 10 simultanÃ©es)
semaphore = asyncio.Semaphore(10)

async def resolve_with_semaphore(position_id):
    async with semaphore:
        return await _resolve_market_by_position_id(position_id, context)

if position_ids_to_resolve:
    resolved_markets = await asyncio.gather(
        *[resolve_with_semaphore(pid) for pid in position_ids_to_resolve],
        return_exceptions=True
    )

    # Mapper les rÃ©sultats
    for position_id, market in zip(position_ids_to_resolve, resolved_markets):
        if market and not isinstance(market, Exception):
            position_id_to_market[position_id] = market
```

**Gain estimÃ©** : 25s â†’ 2.5s (10x plus rapide)

---

### Solution 2 : Cache Redis pour les RÃ©solutions de MarchÃ©

```python
# Dans _resolve_market_by_position_id
cache_key = f"market_resolution:{position_id}"
cached_market = await cache_manager.get(cache_key)
if cached_market:
    return cached_market

# RÃ©soudre le marchÃ©
market = await _resolve_market_by_position_id_internal(position_id, context)

# Mettre en cache (TTL: 10 minutes)
if market:
    await cache_manager.set(cache_key, market, ttl=600)

return market
```

**Gain estimÃ©** : RÃ©duction de 80-90% des appels API pour les marchÃ©s dÃ©jÃ  rÃ©solus

---

### Solution 3 : RÃ©duire le Timeout pour les RÃ©solutions

```python
# CrÃ©er un client avec timeout plus court pour les rÃ©solutions
resolution_client = httpx.AsyncClient(timeout=3.0)  # 3 secondes au lieu de 10
```

**Gain estimÃ©** : RÃ©duction du temps d'attente en cas de problÃ¨me rÃ©seau

---

### Solution 4 : Inclure les URLs dans la RÃ©ponse du Service

Modifier `get_recent_recommendations` pour inclure `polymarket_url` dans la rÃ©ponse, Ã©vitant ainsi une deuxiÃ¨me rÃ©solution.

**Gain estimÃ©** : Ã‰limination complÃ¨te de la deuxiÃ¨me passe de rÃ©solution

---

### Solution 5 : Vraie RequÃªte Batch SQL

```python
# Au lieu de boucler, faire une seule requÃªte
async with get_db() as db:
    result = await db.execute(
        select(Market.id, Market.title, Market.polymarket_url, Market.clob_token_ids)
        .where(
            Market.is_active == True,
            # Utiliser ANY() pour chercher tous les position_ids en une fois
            func.jsonb_array_elements_text(Market.clob_token_ids).in_(position_ids)
        )
    )

    # Mapper les rÃ©sultats
    for market in result:
        for token_id in market.clob_token_ids:
            if token_id in position_ids:
                title_map[token_id] = market.title
                url_map[token_id] = market.polymarket_url
```

**Gain estimÃ©** : N requÃªtes â†’ 1 requÃªte (50x moins de requÃªtes DB)

---

## ğŸ“ˆ Priorisation des Optimisations

1. **ğŸ”´ CRITIQUE** : ParallÃ©liser les rÃ©solutions de marchÃ© (Solution 1)
   - Impact : 10x plus rapide
   - ComplexitÃ© : Moyenne
   - Effort : 2-3 heures

2. **ğŸŸ¡ IMPORTANT** : Cache Redis pour les rÃ©solutions (Solution 2)
   - Impact : 80-90% de rÃ©duction des appels
   - ComplexitÃ© : Faible
   - Effort : 1-2 heures

3. **ğŸŸ¡ IMPORTANT** : Inclure URLs dans la rÃ©ponse du service (Solution 4)
   - Impact : Ã‰limination de la double rÃ©solution
   - ComplexitÃ© : Moyenne
   - Effort : 2-3 heures

4. **ğŸŸ¢ OPTIONNEL** : RÃ©duire timeout (Solution 3)
   - Impact : RÃ©duction des timeouts
   - ComplexitÃ© : TrÃ¨s faible
   - Effort : 30 minutes

5. **ğŸŸ¢ OPTIONNEL** : Vraie requÃªte batch SQL (Solution 5)
   - Impact : Optimisation DB
   - ComplexitÃ© : Ã‰levÃ©e
   - Effort : 4-6 heures

---

## ğŸ¯ Objectif de Performance

**Actuel** : ~26 secondes (typique)
**Cible** : **< 5 secondes** (avec optimisations)

**Gain total estimÃ©** : **5-10x plus rapide**
